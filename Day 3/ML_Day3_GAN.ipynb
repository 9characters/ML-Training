{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ML Day3 GAN.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "j8U5b8we8l3u"
      },
      "source": [
        "#Importing Dependencies\n",
        "import numpy as np\n",
        "%tensorflow_version 1.x\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7pt66UuM8yZ_"
      },
      "source": [
        "#Downloading all thhe data files into the colab\n",
        "!wget http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
        "!wget http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
        "!wget http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
        "!wget http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8us8CM5X6nCW"
      },
      "source": [
        "#Copy the downloaded files into the project folder\n",
        "!mkdir MNIST_Fashion\n",
        "!cp *.gz MNIST_Fashion"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oeHQh7gu7oXz"
      },
      "source": [
        "from tensorflow.examples.tutorials.mnist import input_data\n",
        "mnist = input_data.read_data_sets(\"MNIST_Fashion/\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f8NGS9LP8Uw9"
      },
      "source": [
        "#Training Parameters\n",
        "learning_rate = 0.0002\n",
        "batch_size = 128\n",
        "epochs = 40000"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m1ZvgNHu82Kh"
      },
      "source": [
        "#Network Parameters\n",
        "image_dim = 784 #Image size is 28*28\n",
        "gen_hidd_dim = 256 #No of hidden nodes\n",
        "disc_hidd_dim = 256\n",
        "z_noise_dim = 100"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3br02hYQ9HK0"
      },
      "source": [
        "#Xavier Initialization\n",
        "def xavier_init(shape):\n",
        "  return tf.random_normal(shape = shape, stddev=1./tf.sqrt(shape[0]/2.0))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aUpGWe7B9bwf"
      },
      "source": [
        "#Define weights and bias dictionaries\n",
        "weights = {\"disc_H\": tf.Variable(xavier_init([image_dim, disc_hidd_dim])),\n",
        "           \"disc_final\": tf.Variable(xavier_init([disc_hidd_dim, 1])),\n",
        "           \"gen_H\": tf.Variable(xavier_init([z_noise_dim, gen_hidd_dim])),\n",
        "           \"gen_final\": tf.Variable(xavier_init([gen_hidd_dim, image_dim]))}\n",
        "           \n",
        "bias = {\"disc_H\": tf.Variable(xavier_init([disc_hidd_dim])),\n",
        "        \"disc_final\": tf.Variable(xavier_init([1])),\n",
        "        \"gen_H\": tf.Variable(xavier_init([gen_hidd_dim])),\n",
        "        \"gen_final\": tf.Variable(xavier_init([image_dim]))}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IJ-IgtrA-2kD"
      },
      "source": [
        "#Creating Computational Graph\n",
        "#Define Discriminator Function (Network)\n",
        "def Discriminator(x):\n",
        "  hidden_layer = tf.nn.relu(tf.add(tf.matmul(x, weights[\"disc_H\"]), bias[\"disc_H\"]))\n",
        "  final_layer = tf.add(tf.matmul(hidden_layer, weights[\"disc_final\"]), bias[\"disc_final\"])\n",
        "  disc_output = tf.nn.sigmoid(final_layer)\n",
        "  return disc_output\n",
        "\n",
        "def Generator(z):\n",
        "  hidden_layer = tf.nn.relu(tf.add(tf.matmul(z, weights[\"gen_H\"]), bias[\"gen_H\"]))\n",
        "  final_layer = tf.add(tf.matmul(hidden_layer, weights[\"gen_final\"]), bias[\"gen_final\"])\n",
        "  gen_output = tf.nn.sigmoid(final_layer)\n",
        "  return gen_output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lxQC0RhyIwc1"
      },
      "source": [
        "#Define the placefolders for External Input\n",
        "z_input = tf.placeholder(tf.float32, shape=[None, z_noise_dim], name=\"input_noise\")\n",
        "x_input = tf.placeholder(tf.float32, shape=[None, image_dim], name=\"real_input\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-w4KrzDKL6Zq"
      },
      "source": [
        "#Building Generator Network\n",
        "output_Gen = Generator(z_input)     # G(Z)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kI91U_siMr3_"
      },
      "source": [
        "#Building the Discriminator Network\n",
        "\n",
        "real_output_Disc = Discriminator(x_input)      # D(X)\n",
        "fake_output_Disc = Discriminator(output_Gen)    # D(G(Z))    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nd0GFl6pM_bI"
      },
      "source": [
        "Discriminator_Loss = -tf.reduce_mean(tf.log(real_output_Disc + 0.0001) + tf.log(1.-fake_output_Disc + 0.0001))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C6kWqx_kN9Mq"
      },
      "source": [
        "Generator_Loss = -tf.reduce_mean(tf.log(fake_output_Disc + 0.0001))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PfNEwMSHO9tx"
      },
      "source": [
        "#Define Variables\n",
        "Generator_var = [weights[\"gen_H\"], weights[\"gen_final\"], bias[\"gen_H\"], bias[\"gen_final\"]]\n",
        "Discriminator_var = [weights[\"disc_H\"], weights[\"disc_final\"], bias[\"disc_H\"], bias[\"disc_final\"]]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6WgdrKd7PwP_"
      },
      "source": [
        "#Define the optimizer\n",
        "Discriminator_optimize = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(Discriminator_Loss, var_list= Discriminator_var)\n",
        "\n",
        "Generator_optimize = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(Generator_Loss, var_list=Generator_var)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XH0lRdo2Qc8g"
      },
      "source": [
        "#Initialize the variables\n",
        "init = tf.global_variables_initializer()\n",
        "sess = tf.Session()\n",
        "sess.run(init)\n",
        "\n",
        "for epoch in range(epochs):\n",
        "  x_batch, _ = mnist.train.next_batch(batch_size)\n",
        "\n",
        "  #Generate noise to feed to the discriminator\n",
        "  z_noise = np.random.uniform(-1., 1., size=[batch_size, z_noise_dim])\n",
        "  _, Disc_loss_epoch = sess.run([Discriminator_optimize, Discriminator_Loss], feed_dict={x_input: x_batch, z_input: z_noise})\n",
        "  _, Gen_loss_epoch = sess.run([Generator_optimize, Generator_Loss], feed_dict={z_input: z_noise})\n",
        "\n",
        "  if epoch%2000 == 0:\n",
        "    print(f\"Steps: {epoch}, Generator_Loss: {Gen_loss_epoch}, Discriminator_Loss: {Disc_loss_epoch}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CRxDjvFrThoO"
      },
      "source": [
        "#Testing \n",
        "#Generate Images from noise using the generator network\n",
        "n=6\n",
        "canvas = np.empty((28*n, 28*n))\n",
        "for i in range(n):\n",
        "  #Noise input\n",
        "  z_noise = np.random.uniform(-1., 1., size=[batch_size, z_noise_dim])\n",
        "\n",
        "  #Generate Input From Noise\n",
        "  g = sess.run(output_Gen, feed_dict={z_input: z_noise})\n",
        "\n",
        "  #Reverse colors for better display\n",
        "  g  = -1 * (g-1)\n",
        "  for j in range(n):\n",
        "    #Draw the generated images\n",
        "    canvas[i*28:(i+1)*28, j*28:(j+1)*28] = g[j].reshape([28,28])\n",
        "\n",
        "plt.figure(figsize=(n,n))\n",
        "plt.imshow(canvas, origin=\"upper\", cmap=\"gray\")\n",
        "plt.show()   \n",
        "sess.close()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}